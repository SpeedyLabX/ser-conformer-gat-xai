{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a227da56",
   "metadata": {},
   "source": [
    "# RoBERTa full fine-tune (Kaggle)\n",
    "\n",
    "This notebook runs a full RoBERTa-base fine-tune for the TEXT_BRANCH on Kaggle.\n",
    "\n",
    "Usage notes:\n",
    "- Upload `data/iemocap_manifest.jsonl` as a Kaggle Dataset and add it to the Notebook (recommended).\n",
    "- Use GPU Accelerator (T4 or better).\n",
    "- Adjust `--batch_size`, `--accumulation_steps`, and `--max_length` depending on GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U --upgrade-strategy only-if-needed \"transformers==4.57.1\" \"accelerate>=1.9.0\" \"datasets>=2.14,<3.0\" \"evaluate>=0.4\" \"sentencepiece>=0.1.99\" \"sentence-transformers>=3.0,<4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformers, accelerate, datasets, numpy as np\n",
    "print(\"torch:\", torch.__version__, \"cuda:\", torch.cuda.is_available())\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"accelerate:\", accelerate.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"numpy:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SpeedyLabX/ser-conformer-gat-xai.git\n",
    "%cd ser-conformer-gat-xai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!cp /kaggle/input/slx02-ser-dataset/iemocap_manifest.jsonl data/iemocap_manifest.jsonl\n",
    "!ls -l data || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!WANDB_DISABLED=true WANDB_SILENT=true HF_HUB_DISABLE_TELEMETRY=1 \\\n",
    "python scripts/finetune_roberta.py \\\n",
    "  --manifest data/iemocap_manifest.jsonl \\\n",
    "  --backbone roberta-base \\\n",
    "  --batch_size 8 --accumulation_steps 4 --epochs 100 \\\n",
    "  --max_length 128 --num_class 6 \\\n",
    "  --out_dir /kaggle/working/artifacts/roberta_kaggle \\\n",
    "  --fp16 --gradient_checkpointing \\\n",
    "  --load_best_model_at_end \\\n",
    "  --evaluation_strategy epoch \\\n",
    "  --save_total_limit 5 \\\n",
    "  --early_stopping_patience 5 \\\n",
    "  --lr 1e-5 --use_tqdm \\\n",
    "  --split_by_session --train_sessions 1,2,3,4 --test_sessions 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd140aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/evaluate_text.py \\\n",
    "  --manifest data/iemocap_manifest.jsonl \\\n",
    "  --checkpoint /kaggle/working/artifacts/roberta_kaggle \\\n",
    "  --out_dir /kaggle/working/artifacts/roberta_kaggle \\\n",
    "  --save_confusion_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/evaluate_text.py \\\n",
    "  --manifest data/iemocap_manifest.jsonl \\\n",
    "  --checkpoint /kaggle/working/artifacts/roberta_kaggle \\\n",
    "  --out_dir /kaggle/working/artifacts/roberta_kaggle \\\n",
    "  --save_confusion_plot --map_to_4class"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
