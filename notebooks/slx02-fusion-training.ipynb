{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Training Entry Point\n",
    "\n",
    "This notebook prepares the workspace, installs dependencies, rewrites the config with Kaggle paths, and launches training. Attach the datasets that host:\n",
    "\n",
    "- the repository snapshot (read-only under `/kaggle/input/...`)\n",
    "- pretrained encoders (`artifacts/audio-encoder`, `artifacts/roberta-text-encoder`)\n",
    "- IEMOCAP raw data (`IEMOCAP_full_release`) and `iemocap_manifest.jsonl`\n",
    "\n",
    "Update the constants below if your dataset names differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/ser-conformer-gat-xai\n",
    "!git clone https://github.com/SpeedyLabX/ser-conformer-gat-xai.git \\\n",
    "    /kaggle/working/ser-conformer-gat-xai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "WORK_DIR = Path(\"/kaggle/working/ser-conformer-gat-xai\")\n",
    "ARTIFACTS_DATASET = Path(\"/kaggle/input/text-audio-encoders/pytorch/default/1/artifacts\")\n",
    "IEMOCAP_ROOT = Path(\"/kaggle/input/iemocapfullrelease/IEMOCAP_full_release\")\n",
    "MANIFEST_PATH = Path(\"/kaggle/input/iemocap-manifest-jsonl/iemocap_manifest.jsonl\")\n",
    "\n",
    "assert WORK_DIR.exists(), \"Repository clone missing\"\n",
    "assert ARTIFACTS_DATASET.exists(), \"Encoder dataset path incorrect\"\n",
    "assert IEMOCAP_ROOT.exists(), \"IEMOCAP dataset path incorrect\"\n",
    "assert MANIFEST_PATH.exists(), \"Manifest dataset path incorrect\"\n",
    "\n",
    "# Mirror artifacts into the writable repo tree\n",
    "shutil.copytree(ARTIFACTS_DATASET, WORK_DIR / \"artifacts\", dirs_exist_ok=True)\n",
    "print(\"Workspace ready at\", WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet transformers soundfile scikit-learn pyyaml tqdm matplotlib networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/ser-conformer-gat-xai\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e44f0f",
   "metadata": {},
   "source": [
    "## Adjusting Training Hyperparameters\n",
    "\n",
    "All configuration is driven by YAML. By default, the notebook loads `configs/iemocap.yaml`, which itself extends `configs/base.yaml`. Only the keys you override here will change; everything else falls back to `base.yaml`.\n",
    "\n",
    "Parameters you can override and what they control:\n",
    "\n",
    "- `trainer`\n",
    "  - `epochs`: maximum epochs.\n",
    "  - `batch_size`: mini-batch size.\n",
    "  - `lr`: AdamW learning rate.\n",
    "  - `weight_decay`: AdamW weight decay coefficient.\n",
    "  - `grad_clip`: gradient clipping threshold (`null` disables it).\n",
    "  - `patience`: early-stopping patience in epochs.\n",
    "  - `use_tqdm`: enable per-batch progress bars for train/eval.\n",
    "- `model.audio`\n",
    "  - `checkpoint`: path to the pretrained audio encoder bundle.\n",
    "  - `freeze`: keep the audio encoder frozen (`True`) or fine-tune (`False`).\n",
    "- `model.text`\n",
    "  - `checkpoint`: path to the text encoder weights.\n",
    "  - `proj_dim`: projection size fed into fusion.\n",
    "  - `freeze`: freeze text backbone or fine-tune it.\n",
    "- `model.fusion`\n",
    "  - `gat_heads`: number of GAT attention heads.\n",
    "  - `gat_layers`: number of stacked GAT layers.\n",
    "  - `gat_hidden`: hidden dim per head (after concatenating heads this is the fusion output dim).\n",
    "- `model.loss`\n",
    "  - `type`: `focal` or `cross_entropy`.\n",
    "  - `gamma`: focal loss gamma.\n",
    "  - `class_weights`: class weighting list (or `null`).\n",
    "- `data`\n",
    "  - `split`: random split ratios (train/val/test).\n",
    "  - `session_split`: session-based split if you want fixed test sessions.\n",
    "  - `max_text_len`: tokenizer max length.\n",
    "  - `max_audio_frames`: cap on mel frames.\n",
    "  - `num_workers`: DataLoader workers (on Kaggle we keep 0).\n",
    "- Misc\n",
    "  - `metrics`: which metrics to log (`wa`, `ua`, `f1_macro`, `cm`, ...).\n",
    "  - `artifacts_dir`, `log_dir`: where checkpoints and histories are written.\n",
    "\n",
    "Example: uncomment to override selected values:\n",
    "\n",
    "```python\n",
    "hyperparam_overrides = {\n",
    "    \"trainer\": {\n",
    "        \"epochs\": 80,\n",
    "        \"batch_size\": 8,\n",
    "        \"lr\": 2e-4,\n",
    "        \"use_tqdm\": True,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"fusion\": {\"gat_heads\": 6, \"gat_hidden\": 384},\n",
    "        \"audio\": {\"freeze\": False},\n",
    "        \"text\": {\"proj_dim\": 256, \"freeze\": False},\n",
    "        \"loss\": {\"type\": \"cross_entropy\"},\n",
    "    },\n",
    "    \"data\": {\"split\": {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}},\n",
    "}\n",
    "```\n",
    "\n",
    "Only the keys listed in `hyperparam_overrides` are modified; the rest remain unchanged as defined in `configs/iemocap.yaml` (and, via the `extends` mechanism, in `configs/base.yaml`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "## ------------------------------------------------------------------\n",
    "## Optional: tweak hyperparameters before writing the Kaggle config.\n",
    "## Uncomment and edit the block below to override defaults inherited\n",
    "## from configs/base.yaml. Only keys you set here will override the\n",
    "## base values. The rest remain unchanged.\n",
    "## ------------------------------------------------------------------\n",
    "hyperparam_overrides = {\n",
    "    \"trainer\": {\n",
    "        \"use_tqdm\": True,\n",
    "        # \"epochs\": 80,\n",
    "        # \"batch_size\": 8,\n",
    "        # \"lr\": 2e-4,\n",
    "        # \"weight_decay\": 1e-5,\n",
    "        # \"patience\": 7,\n",
    "    },\n",
    "    # \"model\": {\n",
    "    #     \"fusion\": {\n",
    "    #         \"gat_hidden\": 384,\n",
    "    #         \"gat_heads\": 6,\n",
    "    #         \"gat_layers\": 2,\n",
    "    #     },\n",
    "    #     \"audio\": {\"freeze\": False},\n",
    "    #     \"text\": {\"proj_dim\": 256, \"freeze\": False},\n",
    "    #     \"loss\": {\"type\": \"cross_entropy\"},\n",
    "    # },\n",
    "    # \"data\": {\n",
    "    #     \"split\": {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1},\n",
    "    #     \"max_text_len\": 160,\n",
    "    #     \"max_audio_frames\": 600,\n",
    "    #     \"num_workers\": 2,\n",
    "    # },\n",
    "}\n",
    "\n",
    "def deep_update(base: dict, overrides: dict) -> dict:\n",
    "    out = dict(base)\n",
    "    for key, value in overrides.items():\n",
    "        if isinstance(value, dict) and isinstance(out.get(key), dict):\n",
    "            out[key] = deep_update(out[key], value)\n",
    "        else:\n",
    "            out[key] = value\n",
    "    return out\n",
    "\n",
    "WORK_DIR = Path(\"/kaggle/working/ser-conformer-gat-xai\")\n",
    "cfg_path = WORK_DIR / \"configs\" / \"iemocap.yaml\"\n",
    "cfg = yaml.safe_load(cfg_path.read_text())\n",
    "\n",
    "cfg.setdefault(\"data\", {})\n",
    "cfg[\"data\"][\"root\"] = str(IEMOCAP_ROOT)\n",
    "cfg[\"data\"][\"manifest\"] = str(MANIFEST_PATH)\n",
    "cfg[\"data\"][\"num_workers\"] = 0  # safer on Kaggle\n",
    "cfg.setdefault(\"model\", {})\n",
    "cfg[\"model\"].setdefault(\"audio\", {})\n",
    "cfg[\"model\"][\"audio\"][\"checkpoint\"] = str(WORK_DIR / \"artifacts\" / \"audio-encoder\" / \"conformer_encoder.pkl\")\n",
    "cfg[\"model\"].setdefault(\"text\", {})\n",
    "cfg[\"model\"][\"text\"][\"checkpoint\"] = str(WORK_DIR / \"artifacts\" / \"roberta-text-encoder\")\n",
    "cfg.setdefault(\"trainer\", {})\n",
    "cfg[\"trainer\"][\"batch_size\"] = cfg[\"trainer\"].get(\"batch_size\", 8)\n",
    "cfg[\"artifacts_dir\"] = str(WORK_DIR / \"artifacts\")\n",
    "cfg = deep_update(cfg, hyperparam_overrides)\n",
    "\n",
    "resolved_cfg = WORK_DIR / \"configs\" / \"iemocap_kaggle.yaml\"\n",
    "resolved_cfg.write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "print(\"Resolved config written to\", resolved_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "WORK_DIR = \"/kaggle/working/ser-conformer-gat-xai\"\n",
    "os.chdir(WORK_DIR)\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "result = subprocess.run([\n",
    "    \"python\",\n",
    "    \"-m\",\n",
    "    \"src.cli.train\",\n",
    "    \"--config\",\n",
    "    \"configs/iemocap_kaggle.yaml\",\n",
    "    \"--use_tqdm\",\n",
    "    \"--dry-run\",\n",
    "], check=True)\n",
    "print(\"Dry run return code:\", result.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "WORK_DIR = \"/kaggle/working/ser-conformer-gat-xai\"\n",
    "os.chdir(WORK_DIR)\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "subprocess.run([\n",
    "    \"python\",\n",
    "    \"-m\",\n",
    "    \"src.cli.train\",\n",
    "    \"--config\",\n",
    "    \"configs/iemocap_kaggle.yaml\",\n",
    "    \"--use_tqdm\",\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the saved checkpoint\n",
    "\n",
    "The cell below loads the most recent run directory, restores `best_model.pt`, and reports validation/test metrics. Adjust `RUN_DIR` manually if you want to evaluate a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from serxai.data.datamodule import DataModule\n",
    "from serxai.data.labels import LABELS\n",
    "from serxai.models.multimodal import MultimodalSERModel\n",
    "from serxai.utils import metrics as metrics_mod\n",
    "from serxai.utils.seed import set_seed\n",
    "\n",
    "WORK_DIR = Path(\"/kaggle/working/ser-conformer-gat-xai\")\n",
    "cfg_path = WORK_DIR / \"configs\" / \"iemocap_kaggle.yaml\"\n",
    "cfg = yaml.safe_load(cfg_path.read_text())\n",
    "\n",
    "run_root = (WORK_DIR / cfg.get(\"log_dir\", \"experiments/runs\")).resolve()\n",
    "run_dirs = sorted([p for p in run_root.iterdir() if p.is_dir()])\n",
    "assert run_dirs, f\"No run directories found under {run_root}\"\n",
    "RUN_DIR = run_dirs[-1]\n",
    "print(\"Evaluating run:\", RUN_DIR)\n",
    "\n",
    "ckpt_path = RUN_DIR / \"best_model.pt\"\n",
    "assert ckpt_path.exists(), \"best_model.pt missing; finish training first\"\n",
    "\n",
    "seed = int(cfg.get(\"seed\", 42))\n",
    "set_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg[\"model\"][\"text\"][\"checkpoint\"], local_files_only=True)\n",
    "\n",
    "dm = DataModule(\n",
    "    manifest_path=str(cfg[\"data\"][\"manifest\"]),\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_root=cfg[\"data\"].get(\"root\"),\n",
    "    batch_size=int(cfg[\"trainer\"].get(\"batch_size\", 8)),\n",
    "    num_workers=0,\n",
    "    split=cfg[\"data\"].get(\"split\"),\n",
    "    seed=seed,\n",
    "    session_split=cfg[\"data\"].get(\"session_split\"),\n",
    "    max_text_length=int(cfg[\"data\"].get(\"max_text_len\", 128)),\n",
    "    max_audio_frames=cfg[\"data\"].get(\"max_audio_frames\"),\n",
    ")\n",
    "dm.setup()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "fusion_cfg = cfg[\"model\"].get(\"fusion\", {})\n",
    "text_cfg = cfg[\"model\"].get(\"text\", {})\n",
    "model = MultimodalSERModel(\n",
    "    audio_checkpoint=cfg[\"model\"][\"audio\"][\"checkpoint\"],\n",
    "    text_backbone=cfg[\"model\"][\"text\"][\"checkpoint\"],\n",
    "    text_proj_dim=int(text_cfg.get(\"proj_dim\", 128)),\n",
    "    fusion_hidden=int(fusion_cfg.get(\"gat_hidden\", 256)),\n",
    "    fusion_heads=int(fusion_cfg.get(\"gat_heads\", 4)),\n",
    "    fusion_layers=int(fusion_cfg.get(\"gat_layers\", 2)),\n",
    "    num_classes=len(LABELS),\n",
    "    freeze_audio=bool(cfg[\"model\"][\"audio\"].get(\"freeze\", True)),\n",
    "    freeze_text=bool(text_cfg.get(\"freeze\", True)),\n",
    ").to(device)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def run_eval(loader):\n",
    "    preds, targets = [], []\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            batch = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "            outputs = model(batch)\n",
    "            logits = outputs[\"logits\"]\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "            preds.append(logits.argmax(dim=-1).cpu().numpy())\n",
    "            targets.append(labels.cpu().numpy())\n",
    "    preds_np = np.concatenate(preds)\n",
    "    targets_np = np.concatenate(targets)\n",
    "    metrics = {\n",
    "        \"loss\": total_loss / max(1, total_samples),\n",
    "        \"wa\": metrics_mod.wa(preds_np, targets_np),\n",
    "        \"ua\": metrics_mod.ua(preds_np, targets_np),\n",
    "        \"f1_macro\": metrics_mod.f1_macro(preds_np, targets_np),\n",
    "        \"confusion_matrix\": confusion_matrix(targets_np, preds_np).tolist(),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "val_metrics = run_eval(val_loader)\n",
    "test_metrics = run_eval(test_loader)\n",
    "\n",
    "print(\"Validation metrics:\", json.dumps(val_metrics, indent=2))\n",
    "print(\"Test metrics:\", json.dumps(test_metrics, indent=2))\n",
    "\n",
    "with (RUN_DIR / \"evaluation_metrics.json\").open(\"w\") as fh:\n",
    "    json.dump({\"val\": val_metrics, \"test\": test_metrics}, fh, indent=2)\n",
    "print(\"Saved evaluation metrics to\", RUN_DIR / \"evaluation_metrics.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
